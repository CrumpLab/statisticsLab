[
["lab-9-repeated-measures-anova.html", "Chapter 9 Lab 9: Repeated Measures ANOVA 9.1 Betcha can’t type JHDBZKCO very fast on your first try 9.2 Lab Skills Learned 9.3 Important Stuff 9.4 R 9.5 Excel 9.6 SPSS 9.7 JAMOVI", " Chapter 9 Lab 9: Repeated Measures ANOVA 9.1 Betcha can’t type JHDBZKCO very fast on your first try This lab activity uses the data from Behmer &amp; Crump (2017) to teach one-factor repeated measures ANOVA with-up follow comparisons 9.1.1 STUDY DESCRIPTION Behmer &amp; Crump (2017) used the everyday task of typing on a computer keyboard to ask questions about how people learn to put sequences of actions together. Whenever you type a series of letters on the keyboard, you are putting a sequence of actions together, so typing is task that could be used to measure skilled sequencing. Typing also happens to be a convenient task for measuring sequencing. For example, every time a person types a letter, the timing of the button press and the letter pressed can be measured and stored for later analysis. Behmer &amp; Crump were interested in asking a few different questions, however, we will simplify everything and talk about replication. First we describe an interesting finding from previous research. Behmer &amp; Crump repeated an experiment that should alos produce this same finding. If they succeed in doing this, it means the finding can be replicated, and that it happens in more than one lab. Finding from previous resaearch: Prior research showed that typists do something funny. Skilled typists can type normal words very fast. This suggests they know how to locate all of the letters on the keyboard, and can press each letter very quickly to type words. That part isn’t particulary funny. However, if you take really skilled typists and make them type random letters like this: kwitb dhhgjtryq xkldpt mazhyffdt, guess what happens? They slow down a lot. It’s kind of weird that a typist would slow down, after all they can type letters really fast when they appear in words, but not when they appear in random orders…what gives? Last, it turns out that typists are kind of in the middle in terms of speed, if you ask them to type non-words that have similar properties to words, such as: quenp hamlke phwempy. To summarize, prior research showed that typing speed changes as a function of the structure of the text, roughly in this order from fastest to slowest. (FASTEST) Normal Words &lt; Word-like Non-words &lt; Random strings (SLOWEST) Replication question: Behmer &amp; Crump also measured typists while they typed words, non-words that were english-like, and random strings. They had some additional things they were interested in, but for us, we are interested in whether they would show the same effect. Would they replicate the patten: Normal words (Fastest) &lt; Word-like Non-words (medium) &lt;- Random strings (Slowest)? 9.1.2 Study Methods The authors conducted a repeated measures experiment. A total of 38 subjects were used for the analysis. Independent Variable: The IV Stimulus or typing material had three levels: Normal, Bigrams, and Random. Normal refers to normal 5 letter english words (like truck, or plant). Bigrams refers to non-words that have properties similar to words (e.g., phemt quilp). Random refers to 5 letter strings whose letters were totally random (qmklt gdrzn lprni). Dependent Variables: There were three dependent variables, that all measured different aspects of typing performance. Reaction times (RTs) were defined as the temporal interval between seeing a stimulus (to type), and then starting to type it (first key press). Interkeystroke intervals (IKSIs) are the times between each keypress. Last, accuracy was also measured (correct or incorrect keypresses) The task: Participants (who happened to also be students from Brooklyn College) sat in front a computer. They were presented with one stimulus (word, bigrams, or random) at a time. As soon as they saw the string of letters, they typed it as quickly and accurately as they could, then they moved on to the next trial. Reminder, this is a repeated measures design because each participant typed letter strings from the word, bigrams, and random conditions. 9.2 Lab Skills Learned Conducting a one-factor repeated measures ANOVA Conducting follow-up comparisons 9.3 Important Stuff citation: Behmer, Lawrence P., Crump, M. J. C. (2017). Spatial Knowledge during Skilled Action Sequencing: Hierarchical versus Non-Hierarchical Representations. Attention, Perception &amp; Psychophysics, 79, 2435-2448. Link to .pdf of article Data in .csv format 9.4 R 9.4.1 Load the data Remember that any line with a # makes a comment and the code does not run. Below is how to load the .csv data from the online repository, or from a local file (you need to change the file path to where the local file is, if you downloaded it). The data contains all of the measures and conditions from Experiment 1 in the paper. library(data.table) #all_data &lt;- fread(&quot;https://github.com/CrumpLab/statisticsLab/raw/master/data/exp1_BehmerCrumpAPP.csv&quot;) all_data &lt;- fread(&quot;data/exp1_BehmerCrumpAPP.csv&quot;) 9.4.2 Inspect the dataframe This will give you a big picture of the data frame. Click the button to view it in your browser, then take a look to see what is in it. library(summarytools) view(dfSummary(all_data[,c(1:7,10:20)])) Note, there is some weird stuff in code above. Normally, we would just write view(dfSummary(all_data)), why we add this: all_data[,c(1:7,10:20)]? It turns out the dfSummary function didn’t like some of the data. In particular it didn’t like the data in columns 8 an 9 (notice those numbers are missing, the range inside c is 1 to 7 and 10 to 20). It doesn’t mean the data isn’t there, just that it didn’t want to display it in the viewer. 9.4.3 Get the data you need This data file contains all of the data from Experiment 1 in the paper. So, we don’t need to get rid of any rows. There are numerous columns, some of them we don’t need for the analysis. But, we’ll just ignore these later when we use dplyr to group by the columns we want. The structure of this data a file is in long form. Every row described a measurement for a single keypress. For example, the first 5 rows, have data for the timing of the first 5 keypresses, that the first subject made to type the first string of letters they saw. In total there were 85,410 keypresses made. That’s quite a lot. 9.4.3.1 The independent variable The important independent variable is in the column Stimulus. Normal (5 letter english words) Bigrams (5 letter strings that kind of looked like words) Random (5 letter strings that were random) It is also important to know that the Order column codes the position for each letter, from 1 to 5. Note: there was another independent variable in the study as well. We talk about this later. The second IV is coded in the Block column. Baseline (normal typing, keyboard is visible while typing) Manipulation (occluded typing, keyboard is covered while typing) 9.4.3.2 The dependent variables TimeFromOnset : This column records the temporal interval in milliseconds between the onset of the word and each keypress. When order is 1 (first keystroke), the number here is the reaction time to start typing. PureRTs : This column contains keystroke intervals. The first interval is between the onset of the word and the first keypress (order 1), the second interval is between the first and second keypress (order 2), and so on. PureRTs for orders 2 to 5, represent the interkeystroke intervals reported in paper. AllCorrect : 0 means incorrect (wrong letter was typed), 1 means correct (correct letter was typed) 9.4.4 Look at the data Remember before we do any analysis, we always want to “look” at the data. This first pass let’s us know if the data “look right”. For example, the data file could be messed up and maybe there aren’t any numbers there, or maybe the numbers are just too weird. For example, this study involves reaction times: the time between seeing something and responding to it. If you had done a study like this before, you would know that it usually doesn’t take people that long to start responding. Most reaction times will be under a second (or 1000 millseconds). But, sometime people are little slow, and sometimes they do funny things like check their phone in the middle of an experiment. Before I analyze reaction time data, I often make a histrogram of all of the RT data, like this: hist(all_data$PureRTs) We can see that almost all of the reaction times are well below 5000 milliseconds (5 seconds), which is good. Most of the time people were paying attention and not “checking their phone”. Notice, the range of the histrogram goes out to 15,000 milliseconds. You can’t see any bars out there (too small to notice), but there must be at least a few trials where somebody took 15 seconds to start responding. These are called outliers. We will remove them before we conduct our analysis 9.4.5 Look at the means As part of looking at the data, we might as well make a figure that shows the mean reaction times in each condition, and some error bars to look at the spread in each condition. The following code takes three important steps: Get the means for each subject in each condition. These are put into the data frame called subject_means. Get the means for each condition, by averaging over the means for each subject. These are put into the data frame called plot_means. Make a graph with the plot_means data frame using ggplot2. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:data.table&#39;: ## ## between, first, last ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 3.4.4 all_data$Block&lt;-as.factor(all_data$Block) levels(all_data$Block) &lt;- c(&quot;Visible keyboard&quot;,&quot;Covered Keyboard&quot;) ## get subject mean RTs subject_means &lt;- all_data %&gt;% filter(Order==1, Correct==1, PureRTs&lt;5000) %&gt;% group_by(Subject, Block, Stimulus) %&gt;% summarise(mean_rt = mean(PureRTs)) ## Warning: package &#39;bindrcpp&#39; was built under R version 3.4.4 subject_means$Subject&lt;-as.factor(subject_means$Subject) subject_means$Block&lt;-as.factor(subject_means$Block) subject_means$Stimulus&lt;-as.factor(subject_means$Stimulus) ## get condition mean RTs plot_means &lt;- subject_means %&gt;% group_by(Block, Stimulus) %&gt;% summarise(means = mean(mean_rt), SEs = sd(mean_rt)/sqrt(length(mean_rt))) ## plot the condition means # re-order stimulus factor for plotting plot_means$Stimulus &lt;- factor(plot_means$Stimulus, levels = c(&quot;Normal&quot;, &quot;Bigrams&quot;, &quot;Random&quot;)) ggplot(plot_means, aes(x=Stimulus, y=means, group=Block, color=Block))+ geom_point()+ geom_line()+ geom_errorbar(aes(ymin=means-SEs, ymax=means+SEs), width=.2)+ theme_classic()+ ylab(&quot;Mean Reaction Time (ms)&quot;)+ xlab(&quot;Typing Material&quot;) Alright, we made things a little bit more complicated than they need to be. Our primary question is whether reaction times followed this pattern: Normal &lt; Bigrams &lt; Random. We can see the means do follow this pattern. However, shouldn’t we only be looking at three means, why are their six means, and two lines? The above code included the second independent variable Block. As a result, you are seeing the means for Typing material when subjects could see the keyboard, and when the couldn’t see the keyboard. We will come back to this later. For now, let’s ignore the Block condition, and find the means for the Typing Material IV by averaging over the Block conditions. We run the same code as above, by take out Block, in the group_by function. We also take Block out the ggplot function. VERY IMPORTANT: We did something in the above code that we didn’t point out. We filtered the data before we found the means. For most of the datasets in other labs, we given you data that is more or less ready to analyse. More often than not data needs to be pre-processed, or filtered before you analyze it. We can use the filter function in dplyr to do our filtering. filter filters the rows for us, so we will only include the rows that we want. We want to analyze the time between the onset of the stimulus and the first keystroke. The reaction times for this value are in the PureRTs column, but this column contains other RTs that we do not want to analyse. For example, the Order column codes for the letter position in the string. We only want to analyze the rows that contain a 1, for the first position. So, that is why we add Order==1 to the filter function below. We want to analyze only the reaction times that are correct. That is, when the subject typed the first letter correctly, and did not make a typo. Accuracy is coded in the Correct column, with 1 = correct, and 0 = incorrect. We add Correct==1 to the filtering function. Note the use of ==, that is two equal signs in a row. In R, two equal signs in a row has a special meaning. It means conduct a logic test to determine if one thing is the same as another. We want to analyze only reaction times that are “sensible” to analyze. What does sensible mean? We don’t want to analyze data that is clearly garbage data. For example, if someone fell asleep at the computer and didn’t respond for 15 seconds, that kind of data is not what we want to analyze. If we were to filter the data, and exclude these kinds of outliers, we would be conducting an outlier elimination procedure. Behmer &amp; Crump (2017) did this, and it is commonly done in many different kinds of studies. We skip an extended discussion of outlier elimination for this lab. But, we do introduce the idea of doing it. We want to keep as much of the data as possible. So, what we do is keep all of the RTs that are less than 5000 ms (that’s 5 seconds). To do this, we add PureRTs&lt;5000 to the filter function. ## get subject mean RTs subject_means &lt;- all_data %&gt;% filter(Order==1, Correct==1, PureRTs&lt;5000) %&gt;% group_by(Subject, Stimulus) %&gt;% summarise(mean_rt = mean(PureRTs)) subject_means$Subject&lt;-as.factor(subject_means$Subject) subject_means$Stimulus&lt;-as.factor(subject_means$Stimulus) ## get condition mean RTs plot_means &lt;- subject_means %&gt;% group_by(Stimulus) %&gt;% summarise(means = mean(mean_rt), SEs = sd(mean_rt)/sqrt(length(mean_rt))) ## plot the condition means # re-order stimulus factor for plotting plot_means$Stimulus &lt;- factor(plot_means$Stimulus, levels = c(&quot;Normal&quot;, &quot;Bigrams&quot;, &quot;Random&quot;)) ggplot(plot_means, aes(x=Stimulus, y=means, group=1))+ geom_point()+ geom_line(stat=&quot;identity&quot;)+ geom_errorbar(aes(ymin=means-SEs, ymax=means+SEs), width=.2)+ theme_classic()+ ylab(&quot;Mean Reaction Time (ms)&quot;)+ xlab(&quot;Typing Material&quot;) 9.4.6 Conduct the repeated Measures ANOVA We use the same aov function as we used last time. The only difference is that we add in a new part to the formula. Remember the formula for a one-factor betwee-n subjects ANOVA looked like this: aov( DV ~ IV , dataframe), where DV is the name of the column with your independent variable, IV is the name of the column with your independent variable, and dataframe is the name of your dataframe containing the means in each condition. The formula for a repeated-measures ANOVA looks like this: aov( DV ~ IV + Error(Subject/IV), dataframe). We have added + Error(Subject/IV). This tells R to use the appropriate error term for the repeated measures ANOVA. In the formula, Subject refers to the name of the column coding your subjects (make sure this is a factor in R), and IV is the name of the column for your independent variable. The formula for our data would be: aov( mean_rt ~ Stimulus + Error(Subject/Stimulus), subject_means). Here is the code below. Just as reminder, the raw data codes every single keypress on each row. We don’t want to submit this as the data frame to the aov function. Instead, we need to calculate the data frame for the subject means in each condition. We did that above as a step toward making the graphs. We do it again here to remind you that you need to do this. # get subject means subject_means &lt;- all_data %&gt;% filter(Order==1, Correct==1, PureRTs&lt;5000) %&gt;% group_by(Subject, Stimulus) %&gt;% summarise(mean_rt = mean(PureRTs)) # Make sure IV and Subject are coded as factors subject_means$Subject &lt;- as.factor(subject_means$Subject) subject_means$Stimulus &lt;- as.factor(subject_means$Stimulus) # Conduct the anova aov_out &lt;- aov( mean_rt ~ Stimulus + Error(Subject/Stimulus), subject_means) summary_out &lt;- summary(aov_out) library(xtable) knitr::kable(xtable(summary_out)) Df Sum Sq Mean Sq F value Pr(&gt;F) Residuals 37 3030779.9 81912.970 NA NA Stimulus 2 1157965.2 578982.606 230.5806 0 Residuals1 74 185812.3 2510.977 NA NA Great, we have conducted the ANOVA. We could write up the results of the ANOVA like this: For each subject we computed mean reactions for correct keystrokes in each condition of the Stimulus factor. These means were submitted to a one-factor repeated-measures ANOVA, with Stimulus (Normal, Bigrams, and Random) as the sole factor. The effect of Stimulus was signficant, F(2, 74) = 230.58, MSE = 2510.98, p &lt; 0.001. Note, the p-value shows up as a zero, that’s because it is so small that R doesn’t want to print the actual number 0.000000000000000…1. What does this tell us? The \\(F\\) value we obtained (230.58) almost never occurs by chance. More specifically, the sampling distribution of F from the distribution of no differences virtually never produces a huge F like 230.58 It is super-duper unlikely that chance (sampling error) could have produced the difference we observed. We reject the idea that chance caused the differences, and are very confident that the manipulation (changing the kinds of letters that people have to type), has a causal influence on reaction time in typing. 9.4.6.1 Report the means too Remember, the important goal when conducting analyses, and then writing about them, is to tell people what you did and what you found. This involves more than one step. For this example, we might do three basic things. 1) make a figure to show the means, 2) report the ANOVA so people know if there is support for the inference that the differences between the means are not caused by chance, and 3) report descriptives for the means, so people know what the numbers are (the figure doesn’t show the exact values). We’ve already made the figure and done the ANOVA, let’s report the condition means. To do this, we need to find the means for each condition, collapsing over the means for each subject in each condition. Note that, we already did this to make the figure. Here’s the code again: ## get subject mean RTs subject_means &lt;- all_data %&gt;% filter(Order==1, Correct==1, PureRTs&lt;5000) %&gt;% group_by(Subject, Stimulus) %&gt;% summarise(mean_rt = mean(PureRTs)) subject_means$Subject&lt;-as.factor(subject_means$Subject) subject_means$Stimulus&lt;-as.factor(subject_means$Stimulus) ## get condition mean RTs plot_means &lt;- subject_means %&gt;% group_by(Stimulus) %&gt;% summarise(means = mean(mean_rt), SEs = sd(mean_rt)/sqrt(length(mean_rt))) knitr::kable(plot_means) Stimulus means SEs Bigrams 924.8764 26.69375 Normal 833.1872 24.00055 Random 1077.5361 31.60979 Now, our fu ll write-up of the results would look like this. For each subject we computed mean reactions for correct keystrokes in each condition of the Stimulus factor. These means were submitted to a one-factor repeated-measures ANOVA, with Stimulus (Normal, Bigrams, and Random) as the sole factor. The effect of Stimulus was signficant, F(2, 74) = 230.58, MSE = 2510.98, p &lt; 0.001. The mean reaction time was fastest in the Normal condition (M = 833 ms, SE = 24 ms), followed by the Bigram condition, (M = 924 ms, SE = 27 ms) and slowest in the Random Condition (M = 1078 ms, SE = 32 ms). 9.4.7 Follow-up comparisons The ANOVA tells us that the differences between the means are unlikely to be due to chance. But, remember, this is an ombnibus test. It does not tell us if specific pairs of means are different from one another. To determine whether the difference between two specific means is not likely due to chance, we need to conduct follow-up tests. Because this is a repeated-measures design, we can use the paired-samples t-test for follow-up tests. Let’s do two follow-up tests to confirm that the RTs for Normal words were indeed faster than the RTs for the Bigram condition (word-like non-words); and then, let’s confirm that the RTs for the Bigram condition were indeed faster than the RTs for the Random condition. 9.4.7.1 Normal vs Bigrams We use the subject_means data frame. But, we want to rid of all the rows containing the means from the Random condition. We use filter to do that, then we conduct the paired-samples t-test. comparison_df &lt;- subject_means %&gt;% filter(Stimulus != &quot;Random&quot;) t.test(mean_rt~Stimulus, paired=TRUE, var.equal=TRUE, data = comparison_df) ## ## Paired t-test ## ## data: mean_rt by Stimulus ## t = 12.14, df = 37, p-value = 1.807e-14 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 76.38601 106.99253 ## sample estimates: ## mean of the differences ## 91.68927 9.4.7.2 Bigrams vs Random We use the subject_means data frame. But, we want to rid of all the rows containing the means from the Normal condition. We use filter to do that, then we conduct the paired-samples t-test. comparison_df &lt;- subject_means %&gt;% filter(Stimulus != &quot;Normal&quot;) t.test(mean_rt~Stimulus, paired=TRUE, var.equal=TRUE, data = comparison_df) ## ## Paired t-test ## ## data: mean_rt by Stimulus ## t = -14.212, df = 37, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -174.4245 -130.8949 ## sample estimates: ## mean of the differences ## -152.6597 9.4.8 Reporting everything Now we can look at some write-ups that report everything we did, and everything we want to know. I’ll show you two ways to do it. 9.4.8.1 First way In the first way, we embed the results of the t-test into the description of the mean reaction times. For each subject we computed mean reactions for correct keystrokes in each condition of the Stimulus factor. These means were submitted to a one-factor repeated-measures ANOVA, with Stimulus (Normal, Bigrams, and Random) as the sole factor. The effect of Stimulus was signficant, F(2, 74) = 230.58, MSE = 2510.98, p &lt; 0.001. The mean reaction time was significantly faster in the Normal condition (M = 833 ms, SE = 24 ms), compared to the Bigram condition, (M = 924 ms, SE = 27 ms), t(37) = 12.14, p&lt;0.001. Additionally, mean reactions in the Bigram condition were significantly faster than the Random Condition (M = 1078 ms, SE = 32 ms), t(37) = 14.21, p &lt; 0.001. 9.4.8.2 Second way In the second way, we first report the means as we did the very first time, and then after that we report the t-test results to higlight the size the of the differences between each comparison. For each subject we computed mean reactions for correct keystrokes in each condition of the Stimulus factor. These means were submitted to a one-factor repeated-measures ANOVA, with Stimulus (Normal, Bigrams, and Random) as the sole factor. The effect of Stimulus was signficant, F(2, 74) = 230.58, MSE = 2510.98, p &lt; 0.001. The mean reaction time was fastest in the Normal condition (M = 833 ms, SE = 24 ms), followed by the Bigram condition, (M = 924 ms, SE = 27 ms) and slowest in the Random Condition (M = 1078 ms, SE = 32 ms). Mean reaction times were significantly faster (M = 91 ms) in the Normal than Bigrams condition, t(37) = 12.14, p &lt; 0.001. And, mean reaction times were signifcantly faster (M = 152 ms) in the Bigrams than Random condition, t(37) = 14.21, p &lt; 0.01. There are other ways to write-up statistical results. These are just some example recipes. The important thing is to: Say what the numbers were that you are analyzing Say what the statistical test was Say the results of the statistical test Say what the patterns of means were Say what the follow-up tests were when you test differences between specific means. Add a table or figure so it is easier to “see” the results. 9.4.9 Generalization Exercise Complete the generalization exercise described in your R Markdown document for this lab. 9.4.10 Writing asignment Complete the writing assignment described in your R Markdown document for this lab. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.) 9.5 Excel How to do it in Excel 9.6 SPSS How to do it in SPSS 9.7 JAMOVI How to do it in JAMOVI "]
]
